{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/birddropping/IND5003-Group-Project/blob/main/IND5003_Group_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ql-xU60LnVNY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_demo = pd.read_csv('data/demographic.csv')\n",
    "data_diet = pd.read_csv('data/diet.csv')\n",
    "data_exam = pd.read_csv('data/examination.csv')\n",
    "data_labs = pd.read_csv('data/labs.csv')\n",
    "data_meds = pd.read_csv('data/medications.csv', encoding = \"ISO-8859-1\") # Had to use this encoding standard to read file\n",
    "data_qns = pd.read_csv('data/questionnaire.csv')\n",
    "data_dict = pd.read_excel('NHANES 2014 Dictionary.xlsx')\n",
    "\n",
    "data_vari = pd.read_excel('Variables.xlsx', squeeze = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#glu_data = pd.read_sas('data/GLU_H.XPT') # Fasting glucose was not part of the original dataset. Added from NHANES website\n",
    "#water_data = pd.read_sas('data/DR1TOT_H.XPT')\n",
    "#data_labs = pd.merge(data_labs, glu_data, how='left', on='SEQN')\n",
    "#data_labs = pd.merge(data_labs, water_data, how='left', on='SEQN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the 6 datasets together as 1 with SEQN as the lead. From there, we can trim out the variables that is not needed for our application of diabetes and mental health."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of the dataframes that we wish to combine\n",
    "#data_frames = [data_demo, data_diet, data_exam, data_labs, data_meds, data_qns]\n",
    "#Use the reduce function to merge the datasets on SEQN using an outer merge to not have any data loss\n",
    "#data_merged = reduce(lambda  left,right: pd.merge(left,right,on=['SEQN'], how='outer'), data_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged = data_demo.merge(data_diet, on=['SEQN'], how='left')\n",
    "data_merged = data_merged.merge(data_exam, on=['SEQN'], how='left')\n",
    "data_merged = data_merged.merge(data_labs, on=['SEQN'], how='left')\n",
    "#data_merged = data_merged.merge(data_meds, on=['SEQN'])\n",
    "data_merged = data_merged.merge(data_qns, on=['SEQN'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop duplicates after merge function\n",
    "#data_merged=data_merged.drop_duplicates(subset=['SEQN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset index function\n",
    "#data_merged=data_merged.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vari = data_vari.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = data_vari.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = data_merged[col_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPiXjmxgrZSVwNT4HigtXXl",
   "include_colab_link": true,
   "name": "IND5003 Group Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
